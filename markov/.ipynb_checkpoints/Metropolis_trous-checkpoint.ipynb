{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'Algorithme de Metropolis-Hastings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se donne une loi de probabilité $\\pi$ et on cherche à simuler des variables aléatoires sous cette loi $\\pi$ qu'on appellera la loi cible. L'algorithme de Metropolis-Hastings est une des méthodes possibles pour atteindre ce but. L'algorithme construit de façon itérative une suite de variables aléatoires $(X_n)_{n \\geq 0}$ dont la loi converge vers $\\pi$ quand $n \\rightarrow +\\infty$. Ainsi, lorsque $n$ est \"grand\", un tirage de $X_n$ est presque équivalent à un tirage selon $\\pi$ et en pratique, on approche $\\pi$ par la loi de $X_n$. Pour cette raison, il est très important de quantifier l'erreur d'approximation. On verra qu'au moins dans certains cas l'erreur décroît exponentiellement en $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothèses et description de l'algorithme\n",
    " Pour initialiser l'algorithme, on va se servir d'une autre loi de probabilité $\\mu$ (par exemple, on pourrait prendre $\\mu=\\delta_{x_0}$ pour $x_0\\in E$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme de Metropolis Hastings nécessite deux ingrédients :\n",
    "\n",
    "-  Une proposition de changement $Q:E \\times E \\to[0,1]$ qui est le\n",
    "noyau d'une chaîne de Markov telle que\n",
    " $$\\forall x,y \\in E^2, \\, Q(x,y) > 0 \\iff Q(y,x) > 0.$$\n",
    " On suppose que l'on sait échantillonner les mesures $Q(x,\\cdot)$.\n",
    "- Une fonction d'acceptation $a:E\\times E\\to (0,1]$.\n",
    "\n",
    "L'algorithme construit alors une chaîne de Markov $(X_n)_{n \\ge 0}$ de\n",
    "la façon suivante : à l'itération $n$, $X_n$ étant connu, \n",
    "\n",
    "- On propose un déplacement vers $Y_{n+1}$ suivant la loi $Q(X_n,\\cdot)$ ;\n",
    "- On accepte ce déplacement avec probabilité\n",
    "  $a(X_n,Y_{n+1})$, c'est-à-dire qu'on tire $U_{n}$ de loi\n",
    "  uniforme sur $(0,1)$ et\n",
    "\n",
    "  -    Si $U_{n} \\le a(X_n,Y_{n+1})$, alors $X_{n+1}=Y_{n+1}$ ;\n",
    "  -    Si $U_{n} > a(X_n,Y_{n+1})$, alors $X_{n+1}={X}_{n}$.\n",
    "\n",
    "\n",
    "La matrice de transition $P$ de la chaîne $(X_n)_{n \\geq 0}$ est donc donnée par\n",
    "\n",
    "$$ P(x,y) = \\begin{cases} a(x,y) Q(x,y), \\quad \\forall x,y \\in E, \\quad  \\text{si $x\\neq y$ } \n",
    "\\\\ 1-\\sum_{z \\neq x} a(x,z) Q(x,z), \\quad \\text{si $x=y$}. \\end{cases} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On souhaite que la chaîne de Markov $(X_n)_{n \\geq 0}$ soit réversible par rapport à\n",
    "  $\\pi$, c'est-à-dire :\n",
    "  \n",
    "$$\\forall x,y, \\qquad   \\pi(x) P(x,y) = \\pi(y) P(y,x).$$\n",
    "\n",
    "Pour cette raison, on impose une certaine structure sur la fonction d'acceptation $a$, qui est de la forme\n",
    "\n",
    "$$  \\forall x,y \\in E, \\quad   a(x,y)=\\lambda(x,y) F(r(x,y)), $$\n",
    "\n",
    "\n",
    "où\n",
    "\n",
    "- $F:\\mathbb{R}_+ \\to (0,1]$ est une fonction telle que\n",
    "\n",
    "    $$\\forall z>0, \\quad F(z)=z \\, F\\left(\\frac{1}{z}\\right). $$\n",
    "\n",
    "\n",
    "- $\\lambda: E \\times E \\to \\mathbb{R}$ est une fonction telle que $\\lambda(x,y)=\\lambda(y,x)$ pour tout $x \\neq y$ vérifiant $Q(x,y)>0$.\n",
    "\n",
    "\n",
    "\n",
    "- $r(x,y)$ est le rapport de Metropolis-Hastings :\n",
    "$$ r(x,y)=\\frac{\\pi(y) Q(y,x)}{\\pi(x) Q(x,y)}.$$\n",
    "\n",
    "Deux choix classiques sont\n",
    "\n",
    "- La règle de Barker : $\\lambda=1$ et $F(z)=\\frac{z}{1+z}$.\n",
    "- La règle de Metropolis-Hastings : $\\lambda=1$ et $F(z)= \\min(1,z)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n",
    "\n",
    "Dans la suite, nous allons étudier deux implémentations différentes de l'algorithme pour la même loi cible. Le but est de mettre en évidence la sensibilité de la vitesse de convergence au choix de la règle d'acceptation $a(.,.)$ et à la proposition de changement $Q(.,.)$. Plus précisément, nous verrons qu'avec une version locale de la matrice $Q$, la chaîne de Markov risque de rester bloquée dans les puits, ce qui donne une mauvaise vitesse de convergence. Avec une proposition de changement $Q$ plus globale, on obtient de bien meilleurs résultats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loi cible\n",
    "\n",
    "Considérons une loi cible $\\pi$ sur l'espace d'états $E=\\{0,..,2l\\}$ avec deux puits : \n",
    "\n",
    "$$ \\forall x\\in E,\\quad \\pi(x) = \\frac{2^{|x-l| }}{4(2^l-1)+1 }.$$\n",
    "\n",
    "La distance entre les puits est déterminée par le paramètre $l$.\n",
    "\n",
    "Remarque : si $\\pi(x)>0$ pour tout $x$, on peut écrire $\\pi(x)= e^{-V(x)}$ et $V$ est appelé le potentiel, de sorte que le voisinage d'un maximum local pour $\\pi$ correspond au voisinage d'un minimum local, ou \"puits\", pour le potentiel $V$. C'est en ce sens qu'il faut comprendre la dénomination \"puits\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# Longueur des puits\n",
    "l=5\n",
    "\n",
    "# Espace d'etats\n",
    "L=2*l\n",
    "\n",
    "# Construction loideuxpuits\n",
    "loideuxpuits=np.ones(L+1) \n",
    "for i in range(L+1):\n",
    "    loideuxpuits[i]=2**(abs(i-l))/(4*(2**l-1)+1)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.title('Loi à deux puits')\n",
    "plt.plot(np.array(range(L+1)), -np.log(loideuxpuits),'ro')\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"-log($\\pi(x)$)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version locale \n",
    "\n",
    " Considérons dans un premier temps une  proposition de changement locale donnée par\n",
    "\n",
    "$$\\forall x,y\\in E, \\quad  Q(x,y) = \\frac{1}{2}, \\quad\\mbox{si $|x-y|=1$ ou $x=y=0$, ou $x=y=2l$. } $$\n",
    "\n",
    "Cette matrice revient à choisir un voisin au hasard (sauf aux bords).  \n",
    "\n",
    "\n",
    "Le rapport de Metropolis-Hastings (calculé seulement pour les couples $(x,y)$ tels que $x\\neq y$ et $Q(x,y)>0$) est\n",
    "\n",
    "$$ r(x,y) = \\begin{cases} 2  \\quad \\text{si $|y-l| = |x-l|+1$}\\\\ 1/2 \\quad \\text{si $|y-l| = |x-l|-1$} \n",
    "\\end{cases}  $$\n",
    "\n",
    "On utilise la règle de Barker, i.e.\n",
    "\n",
    "\n",
    "$$ \\lambda \\equiv 1, \\quad F(z) = \\frac{z}{1+z} $$\n",
    "\n",
    "La fonction d'acceptation se calcule explicitement\n",
    "\n",
    "$$ a(x,y) = \\begin{cases} 2/3  \\quad \\text{si $|y-l| = |x-l|+1$}\\\\ 1/3 \\quad \\text{si $|y-l| = |x-l|-1$}  \\end{cases} $$\n",
    "\n",
    "et on en déduit la matrice de transition de l'algorithme de Metropolis-Hastings\n",
    "\n",
    "$$ P(x,y) = \\begin{cases}  1/3, \\quad \\mbox{si $|y-l|=|x-l|+1$ et $ x\\notin\\{0,2l\\}$  } \\\\ 1/6,  \\quad \\mbox{si $|y-l|=|x-l|-1$} \\\\ 1/2,  \\quad \\mbox{si $x=y$  and $x\\notin\\{0,l,2l\\}$}\\\\ 1/3 , \\quad \\mbox{si $x=y=l$} \\\\5/6, \\quad \\mbox{si $x=y$, and $ x\\in\\{0,2l\\}$} \\end{cases} $$\n",
    "\n",
    "Dans la suite, nous allons construire les fonctions élémentaires permettant de définir numériquement la fonction d'acceptation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction identifie les 2 états qui ont une probabilité positive d'être proposés\n",
    "# quand la chaîne se trouve en x\n",
    "def neighbors(x):\n",
    "    \n",
    "    if x ==0 :\n",
    "        neigh= [x,x+1]\n",
    "    \n",
    "    elif x==L:\n",
    "        neigh= [x-1,x]\n",
    "    \n",
    "    else:\n",
    "        neigh=[x-1,x+1]\n",
    "    \n",
    "    return neigh\n",
    "\n",
    "\n",
    "# Définition de la matrice Q\n",
    "\n",
    "Q=np.zeros((L+1,L+1))\n",
    "\n",
    "for x in range(L+1):\n",
    "    for y in range(L+1):\n",
    "        if y in neighbors(x):\n",
    "            Q[x][y]=1/2\n",
    "\n",
    "# Rapport de Metropolis-Hastings\n",
    "def r(x,y,cible):\n",
    "    \n",
    "    return ###TROU###  \n",
    "\n",
    "\n",
    "# Taux d'acceptation avec la règle de Barker\n",
    "def barkeracceptance(x,y,cible):\n",
    "    \n",
    "    return ###TROU###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La proposition locale est choisie selon la loi uniforme sur l'ensemble des voisins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposition locale : choix uniforme parmi les voisins\n",
    "def localproposition(x):\n",
    "    \n",
    "    return random.choice(neighbors(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " L'état initial $X_0$ est tiré selon la loi uniforme. On choisit le nombre d'itérations de l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0=np.random.choice(list(range(L)),1)[0]\n",
    "\n",
    "Niter=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante implémente l'algorithme de Metropolis-Hastings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MHlocal(X0,Niter,cible):\n",
    "    \n",
    "    Xseq=[X0] # Xseq contient la suite (X_n) des états visités par l'algorithme\n",
    "    \n",
    "  ###TROU###\n",
    "    \n",
    "    return Xseq\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lançant l'algorithme, on observe que la trajectoire de la chaîne  de Markov $(X_n)$ reste principalement localisée autour des puits $0$ et $2 l$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=MHlocal(X0,Niter,loideuxpuits)\n",
    "plt.figure(2)\n",
    "plt.ylim(0,L)  \n",
    "plt.title('Chaîne de Metropolis-Hastings')\n",
    "plt.plot(X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version locale : expériences numériques\n",
    "\n",
    "\n",
    "### Distance en fonction du point de départ\n",
    "Nous allons maintenant étudier numériquement la vitesse de convergence de l'algorithme en utilisant une méthode Monte Carlo. Pour cela, nous allons construire des histogrammes pour approcher la loi de $X_{Niter}$ pour différents choix du point de départ $X_0$. Nous calculerons ensuite la distance en variation totale entre l'histogramme et la loi cible $\\pi$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Fonction qui calcule la distance en variation totale\n",
    "def totvardist(p,q):\n",
    "    d= 0.5*sum(np.abs(p-q));\n",
    "    return d\n",
    "\n",
    "\n",
    "# Fonction qui retourne un échantillon de Nsamples de X_{Niter} pour la version locale\n",
    "def MCtestloc(X0,Niter,Nsamples,cible):\n",
    "   \n",
    "    ###TROU###\n",
    "        \n",
    "    return echantillon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons construire un histogramme pour chaque point de départ. On prend $N_{iter}=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Nsamples=5000 # taille de l'echantillon utilisé pour construire les histogrammes\n",
    "\n",
    "Niter=10\n",
    "\n",
    "plt.figure(3)\n",
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "# Ici on affiche les histogrammes. Le code est un peu compliqué afin de pouvoir \n",
    "# fonctionner pour une distance 2l arbitraire entre les puits. \n",
    "\n",
    "spacing=(L+1)//11  #construction de la grille des points de départ pour l'affichage\n",
    "listofinitialpoints= spacing* list(range(12))\n",
    "listofinitialpoints= [i for i in listofinitialpoints if i <=L]\n",
    "\n",
    "\n",
    "for i in listofinitialpoints:\n",
    "        X0= i\n",
    "        echantillon=MCtestloc(X0,Niter,Nsamples,loideuxpuits)\n",
    "        plt.subplot(4,3, listofinitialpoints.index(i)+1)\n",
    "        plt.hist(echantillon,L+1,range=(-0.5,L+1-0.5),density=True)\n",
    "        plt.title(\"X0=\" + str(i)+\",  \" \"Niter =\"+ str(Niter))\n",
    "        plt.plot(loideuxpuits,'ro')\n",
    "        plt.axis([-1, L+1, 0, 1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que :\n",
    "\n",
    "- Les histogrammes dépendent fortement du point de départ ;\n",
    "- Les histogrammes ne semblent pas bien décrire la loi cible, car ils sont principalement concentrés sur un des deux puits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut étudier la distance en variation totale en fonction du point de départ, pour un nombre d'itérations $N_{iter}$ fixé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choix des paramètres\n",
    "Niter=5\n",
    "\n",
    "# On va conserver ici les valeurs de la distance\n",
    "distseqlocalstart=np.ones(L+1)\n",
    "\n",
    "for i in range(L+1):\n",
    "    X0=i\n",
    "    echantillon=MCtestloc(X0,Niter,Nsamples,loideuxpuits)\n",
    "    histo=np.histogram(echantillon,L+1,range=(-0.5,L+1-0.5),density=True)\n",
    "    distseqlocalstart[i]=totvardist(histo[0],loideuxpuits)\n",
    "\n",
    "plt.figure(4)\n",
    "plt.title(\"distance en variation totale après  \" + str(Niter) + \"  itérations \")\n",
    "plt.ylabel(\"distance\")\n",
    "plt.xlabel(\"point de départ\")\n",
    "plt.ylim(0,1)\n",
    "plt.plot(distseqlocalstart,'bs')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance en fonction du nombre d'itérations\n",
    "\n",
    "\n",
    "Pour un point de départ fixé, on peut étudier numériquement la distance en variation totale en fonction du nombre d'itérations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix du point de départ \n",
    "X0=3\n",
    "\n",
    "# Nombre max d'itérations affiché dans le plot\n",
    "Niter=8\n",
    "\n",
    "# On va conserver ici les valeurs de la distance en variation totale\n",
    "distseqlocalniter=np.ones(Niter+1)\n",
    "\n",
    "for i in range(Niter+1):\n",
    "    echantillon=MCtestloc(X0,i,Nsamples,loideuxpuits)\n",
    "    histo=np.histogram(echantillon,L+1,range=(-0.5,L+1-0.5),density=True)\n",
    "    distseqlocalniter[i]=totvardist(histo[0],loideuxpuits)\n",
    "\n",
    "plt.figure(5)\n",
    "plt.ylim(0,1.2)\n",
    "plt.plot(distseqlocalniter,'b^')\n",
    "plt.ylabel(\"distance\")\n",
    "plt.xlabel(\"n. itérations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version globale\n",
    "\n",
    "La version locale de l'algorithme de Metropolis-Hastings converge difficilement car la chaîne de Markov $(X_n)$ reste bloquée dans les puits. Pour éviter ce problème, considérons une proposition de changement $Q(.,.)$ globale en choisissant un site uniformément parmi tous les états possibles $\\{0,..,2l\\}$. Il s'agit d'un changement majeur car la proposition ne dépend plus de l'état courant $x$ :\n",
    "\n",
    "$$ \\forall x,y \\in E, \\quad Q(x,y) = \\frac{1}{2l +1}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q=(np.ones((L+1,L+1)))/(L+1)\n",
    "\n",
    "def globalproposition():\n",
    "    \n",
    "    return random.choice(range(L+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela nous donne comme rapport de Metropolis\n",
    "\n",
    "$$ \\forall x,y\\in E, \\quad \\quad r(x,y) =  2^{|y-l| - |x-l|}. $$\n",
    "\n",
    "Pour définir la fonction d'acceptation, on utilise la règle de Metropolis, i.e. \n",
    "\n",
    "$$ \\lambda(x,y)\\equiv 1, \\quad F(z) = \\min(1,z). $$\n",
    "\n",
    "d'où la fonction d'acceptation\n",
    "$$ a(x,y) = \\begin{cases} 2^{|y-l| - |x-l|} , \\quad & \\mbox{si $x \\neq y$, $|y-l|<|x-l|$}\\\\ 1 \\quad &\\mbox{si $x \\neq y$, $|y-l|\\geq|x-l|$} \\end{cases}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolisacceptance(x,y,cible):\n",
    "    \n",
    "    return ###TROU###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous, une implémentation de la version globale de l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MHglobal(X0,Niter,cible):\n",
    "    \n",
    "       Xseq=[X0]  # Xseq contient la suite des états (X_n) visités par l'algorithme\n",
    "    \n",
    "       for n in range(Niter):\n",
    "        \n",
    "        Xn=Xseq[-1]\n",
    "        \n",
    "        y=globalproposition()\n",
    "        \n",
    "        U=np.random.rand(1)[0]\n",
    "        \n",
    "        if  U <= metropolisacceptance(Xn,y,cible):\n",
    "            Xseq+=[y]\n",
    "        \n",
    "        else:\n",
    "            Xseq+=[Xn]\n",
    "    \n",
    "       return Xseq\n",
    "         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lançant l'algorithme, on observe que la trajectoire $(X_n)$ explore plus rapidement l'espace d'états qu'auparavant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Niter=300\n",
    "\n",
    "X=MHglobal(X0,Niter,loideuxpuits)\n",
    "\n",
    "plt.figure(6)\n",
    "plt.title('Chaîne de Metropolis-Hastings')\n",
    "plt.plot(X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version globale : expériences numériques\n",
    "\n",
    "\n",
    "### Distance en fonction du point de départ\n",
    "\n",
    "\n",
    "On effectue les mêmes tests que précédemment. On commence par les histogrammes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redéfinition des paramètres\n",
    "Niter=10\n",
    "\n",
    "# Définition de la fonction utilisée dans la méthode Monte Carlo pour la version globale\n",
    "def MCtestglob(X0,Niter,Nsamples,cible):\n",
    "    echantillon=[]\n",
    "    \n",
    "    for k in range(Nsamples):\n",
    "        \n",
    "        echantillon += [MHglobal(X0,Niter,cible)[-1]]\n",
    "        \n",
    "        MHglobal(X0,Niter,cible)\n",
    "        \n",
    "    return echantillon\n",
    "\n",
    "\n",
    "Nsamples=5000 # taille de l'échantillon utilisé pour construire les histogrammes\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(7)\n",
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "spacing=(L+1)//11\n",
    "listofinitialpoints= spacing* list(range(12))\n",
    "listofinitialpoints= [i for i in listofinitialpoints if i <=L]\n",
    "\n",
    "\n",
    "for i in listofinitialpoints:\n",
    "        X0= i\n",
    "        echantillon=MCtestglob(X0,Niter,Nsamples,loideuxpuits)\n",
    "        plt.subplot(4,3, listofinitialpoints.index(i)+1)\n",
    "        plt.hist(echantillon,L+1,range=(-0.5,L+0.5),density=True)\n",
    "        plt.title(\"X0=\" + str(i)+\",  \" \"Niter =\"+ str(Niter))\n",
    "        plt.plot(loideuxpuits,'ro')\n",
    "        plt.axis([-1, L+1, 0, 1])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On observe que :\n",
    "\n",
    "- Les histogrammes sont presque indépendants du point de départ ;\n",
    "- Les histogrammes semblent très bien décrire la loi cible.\n",
    "\n",
    "\n",
    "\n",
    "Comparons maintenant la distance en variation totale par rapport aux points de départ pour les deux choix de $Q$, c'est-à-dire version locale versus version globale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des paramètres\n",
    "Niter=5\n",
    "Nsamples=20000\n",
    "\n",
    "distseqglobstart=np.ones(L+1)\n",
    "\n",
    "for i in range(L+1):\n",
    "    X0=i\n",
    "    echantillon=MCtestglob(X0,Niter,Nsamples,loideuxpuits)\n",
    "    histo=np.histogram(echantillon,L+1,range=(-0.5,L+0.5),density=True)\n",
    "    distseqglobstart[i]=totvardist(histo[0],loideuxpuits)\n",
    "\n",
    "plt.figure(8)\n",
    "plt.ylim(0,0.8)\n",
    "glob, =plt.plot(distseqglobstart,'rs',label='globale') \n",
    "loc, =plt.plot(distseqlocalstart,'bs',label='locale')\n",
    "plt.legend(handles=[glob, loc])\n",
    "plt.ylabel(\"distance\")\n",
    "plt.xlabel(\"point de départ\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Distance en fonction du nombre d'itérations\n",
    "\n",
    "\n",
    "\n",
    "De même, si on regarde la dépendance en temps pour un point de départ fixé on trouve :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choix des paramètres\n",
    "X0=3\n",
    "Nsamples=20000\n",
    "Niter=8\n",
    "\n",
    "\n",
    "# On va conserver ici les valeurs de distance\n",
    "distseqglobniter=np.ones(Niter+1)\n",
    "\n",
    "for i in range(Niter+1):\n",
    "    echantillon=MCtestglob(X0,i,Nsamples,loideuxpuits)\n",
    "    histo=np.histogram(echantillon,L+1,range=(-0.5,L+0.5),density=True)\n",
    "    distseqglobniter[i]=totvardist(histo[0],loideuxpuits)\n",
    "\n",
    "plt.figure(9)\n",
    "plt.ylim(0,1.2)\n",
    "\n",
    "glob, =plt.plot(distseqglobniter,'r^',label='glob') \n",
    "loc, =plt.plot(distseqlocalniter,'b^',label='loc')\n",
    "plt.legend(handles=[glob, loc])\n",
    "plt.ylabel(\"distance\")\n",
    "plt.xlabel(\"n. itérations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vitesse de convergence exponentielle\n",
    "\n",
    "\n",
    "Un calcul théorique montre que si l'on définit\n",
    "\n",
    "$$\n",
    "\\frac{1}{K}=\\inf_{x\\in E} \\,  \\frac{1}{(2l+1)\\pi(x)},\n",
    "$$\n",
    "\n",
    "alors pour tout point de départ $x$ et tout temps $N$, on a \n",
    "\n",
    "$$ d_{TV}(\\mbox{loi}(X_{N}),\\pi) \\leq d_{TV}(\\delta_x ,\\pi) (1-1/K)^N $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut vérifier numériquement cette prédiction théorique avec une méthode Monte Carlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des paramètres\n",
    "X0=3\n",
    "\n",
    "\n",
    "# Constante K\n",
    "K = (L+1)* np.max(loideuxpuits)\n",
    "\n",
    "# Mesure de Dirac\n",
    "diracX0=np.zeros(L+1); diracX0[X0+1]=1;\n",
    "\n",
    "# Prédiction théorique de de distance\n",
    "predtheor= np.ones(Niter+1) \n",
    "for i in range(Niter+1):\n",
    "    predtheor[i]=((1-1/K)**i)*totvardist(diracX0,loideuxpuits)\n",
    "    \n",
    "    \n",
    "plt.figure(10)   \n",
    "theor, =plt.plot(distseqglobniter,'blue', label='Borne expérimentale') # vitesse de convergence expérimentale\n",
    "exp, =plt.plot(predtheor,'red',label='Borne théorique') # borne théorique \n",
    "plt.legend(handles=[theor, exp])\n",
    "plt.ylabel(\"distance\")\n",
    "plt.xlabel(\"n. itérations\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
